# DisinfoMM

**DisinfoMM** is a multilingual and multimodal dataset for disinformation and out-of-context (OOC) detection, released with our ICMI 2025 paper. The dataset includes fact-checked claims with paired images and multilingual evidence, supporting five-level veracity classification and evidence-aware model training.

ğŸ“„ **Paper**: [A Multilingual, Multimodal Dataset for Disinformation and Out-of-Context Analysis with Rich Supportive Information (ICMI 2025)](https://doi.org/10.1145/3716553.3750813)

---

## ğŸ“¦ Dataset Overview

- **Languages**: English, Italian, Portuguese
- **Modalities**: Text (claim), Image
- **Veracity Labels**: `True`, `Mostly True`, `Incomplete`, `Mostly False`, `False`
- **Supportive Information**:
  - Explanation texts
  - Debunking source metadata (verdict, timestamp, keywords, article links)
  - External links and multilingual evidence

---

## ğŸ§ª Tasks Supported

- Multimodal disinformation detection
- Out-of-context imageâ€“text analysis
- Evidence-aware veracity classification
- Multilingual generalization benchmarking

---

## ğŸ› ï¸ Repository Structure

```bash
DisinfoMM/
â”œâ”€â”€ data/                  # (Coming soon) Dataset files, organized by language or split
â”œâ”€â”€ code/                  # (Planned) Baseline models and preprocessing scripts
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸš§ Status

This repository is under preparation. The dataset and code will be released soon.

Please â­ï¸ star or watch the repo to stay updated.

---

## ğŸ“¬ Contact

If you have questions or would like early access, feel free to contact:

**Shuhan Cui**  
The University of Tokyo  
ğŸ“§ syokan [at] g.ecc.u-tokyo.ac.jp
